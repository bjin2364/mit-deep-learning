{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Building an MNIST Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "260962a02c6743518add1429c3ddac39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec5f2eaab3e347b99c556a0291989a90",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20325ca462ef4021a2be9c29ad84faaf",
              "IPY_MODEL_59e68f6c75374394a411f16e979d2f25"
            ]
          }
        },
        "ec5f2eaab3e347b99c556a0291989a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20325ca462ef4021a2be9c29ad84faaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e8750a0dea54d189b9454d7b267f223",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4671a11a0224e0696481697e2232787"
          }
        },
        "59e68f6c75374394a411f16e979d2f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6370dd280d043d99e4c768dc522fc34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [07:57&lt;00:00, 20740.49it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d9317a687a7461580106b6967e73963"
          }
        },
        "2e8750a0dea54d189b9454d7b267f223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4671a11a0224e0696481697e2232787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6370dd280d043d99e4c768dc522fc34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d9317a687a7461580106b6967e73963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f8690d09cf74d15acd489e32e1d6e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e929527c0b14bd88324f1c41ab0aaf1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_546d9cbb32254225846d56171d5abc63",
              "IPY_MODEL_e33d72aefed441f09a0b2dec1761f8ad"
            ]
          }
        },
        "2e929527c0b14bd88324f1c41ab0aaf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "546d9cbb32254225846d56171d5abc63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08a56ff6aa2f4e8ea22e73b4da9f8ab9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f7146794f9343ffbc1415004c933f62"
          }
        },
        "e33d72aefed441f09a0b2dec1761f8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f339d58f7d6457fbf046385bef7f720",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [03:33&lt;00:00, 138.86it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a25a3a5481441f4b1b4d02207412e8e"
          }
        },
        "08a56ff6aa2f4e8ea22e73b4da9f8ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f7146794f9343ffbc1415004c933f62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f339d58f7d6457fbf046385bef7f720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a25a3a5481441f4b1b4d02207412e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb69f168a43d451ab241a5dc7ed59486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_664b94346fea4888bd7e86ee12b7f9ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_50b83c68f5a64819abb61041f9595f01",
              "IPY_MODEL_68009ed6813642178d1053a20455baf6"
            ]
          }
        },
        "664b94346fea4888bd7e86ee12b7f9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50b83c68f5a64819abb61041f9595f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc6a887d5fcc400892726edce088109c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2257cb5ebec84d05b0cc30fdc3adb78c"
          }
        },
        "68009ed6813642178d1053a20455baf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec250471e80c47e5afe7c886f6c420f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:47&lt;00:00, 34494.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8829c01cce9049478fbe2e234c4005e1"
          }
        },
        "bc6a887d5fcc400892726edce088109c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2257cb5ebec84d05b0cc30fdc3adb78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec250471e80c47e5afe7c886f6c420f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8829c01cce9049478fbe2e234c4005e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "635d11af27fb439baaad405699c91625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffcb4e62713d43d590ed0858b86eb34c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb668c6a68024ac69913803840804fc8",
              "IPY_MODEL_e4eb2f9f1b6344dd94eb8c4f196b62b1"
            ]
          }
        },
        "ffcb4e62713d43d590ed0858b86eb34c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb668c6a68024ac69913803840804fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6998c30504064ebd96dfc1cf74ff2450",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10abd83d12244d8d940d81748fe2141a"
          }
        },
        "e4eb2f9f1b6344dd94eb8c4f196b62b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19cb05f2ff6347d8b38ec20436a5cbb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 49627.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2852f475c8c4473286c088809cf6c72c"
          }
        },
        "6998c30504064ebd96dfc1cf74ff2450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10abd83d12244d8d940d81748fe2141a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19cb05f2ff6347d8b38ec20436a5cbb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2852f475c8c4473286c088809cf6c72c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjin2364/mit-deep-learning/blob/main/Building_an_MNIST_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8BTIAeOuhwa"
      },
      "source": [
        "## NOTE: Click the top-left \"Open In Playground\" button! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6b1o-YeTJDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b22ecd-1249-40c1-da2f-bb7308841135"
      },
      "source": [
        "# install basical image libs\n",
        "!pip install Pillow>=5.0.0\n",
        "!pip install -U image\n",
        "\n",
        "# install torch and torchvision (a utility library for computer vision that provides many public datasets and pre-trained models)\n",
        "from os.path import exists\n",
        "#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting image\n",
            "  Downloading image-1.5.33.tar.gz (15 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from image) (7.1.2)\n",
            "Collecting django\n",
            "  Downloading Django-3.2.5-py3-none-any.whl (7.9 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.9 MB 30.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from image) (1.15.0)\n",
            "Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from django->image) (0.4.1)\n",
            "Collecting asgiref<4,>=3.3.2\n",
            "  Downloading asgiref-3.4.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from django->image) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from asgiref<4,>=3.3.2->django->image) (3.7.4.3)\n",
            "Building wheels for collected packages: image\n",
            "  Building wheel for image (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image: filename=image-1.5.33-py2.py3-none-any.whl size=19495 sha256=cc39827bee1f861dc16fa01c01385084f5559e53f94a2818fdcb83af206d4008\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/88/e6/897194cfe8c08a8b9afd881d3bf53d102e13fa39607d721383\n",
            "Successfully built image\n",
            "Installing collected packages: asgiref, django, image\n",
            "Successfully installed asgiref-3.4.1 django-3.2.5 image-1.5.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13PbnpgoQNha"
      },
      "source": [
        "## Building an MNIST Classifier\n",
        "\n",
        "\n",
        "Using what we have learned, let's build a simple MNIST digits classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI0tjLy2VUkj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "torch.manual_seed(1234)  # for reproducibility\n",
        "\n",
        "cuda0 = torch.device('cuda:0')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f6eG5KSOKw"
      },
      "source": [
        "### Loading Data\n",
        "\n",
        "The [`torchvision`](https://pytorch.org/docs/stable/torchvision/index.html) library provides a wide range of standard vision datasets and networks with pretrained weights. We will use [the `torchvision.datasets.MNIST` class](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist) to easily access the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YutSDfPfR_Eg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539,
          "referenced_widgets": [
            "260962a02c6743518add1429c3ddac39",
            "ec5f2eaab3e347b99c556a0291989a90",
            "20325ca462ef4021a2be9c29ad84faaf",
            "59e68f6c75374394a411f16e979d2f25",
            "2e8750a0dea54d189b9454d7b267f223",
            "a4671a11a0224e0696481697e2232787",
            "e6370dd280d043d99e4c768dc522fc34",
            "8d9317a687a7461580106b6967e73963",
            "4f8690d09cf74d15acd489e32e1d6e05",
            "2e929527c0b14bd88324f1c41ab0aaf1",
            "546d9cbb32254225846d56171d5abc63",
            "e33d72aefed441f09a0b2dec1761f8ad",
            "08a56ff6aa2f4e8ea22e73b4da9f8ab9",
            "1f7146794f9343ffbc1415004c933f62",
            "0f339d58f7d6457fbf046385bef7f720",
            "6a25a3a5481441f4b1b4d02207412e8e",
            "cb69f168a43d451ab241a5dc7ed59486",
            "664b94346fea4888bd7e86ee12b7f9ab",
            "50b83c68f5a64819abb61041f9595f01",
            "68009ed6813642178d1053a20455baf6",
            "bc6a887d5fcc400892726edce088109c",
            "2257cb5ebec84d05b0cc30fdc3adb78c",
            "ec250471e80c47e5afe7c886f6c420f1",
            "8829c01cce9049478fbe2e234c4005e1",
            "635d11af27fb439baaad405699c91625",
            "ffcb4e62713d43d590ed0858b86eb34c",
            "fb668c6a68024ac69913803840804fc8",
            "e4eb2f9f1b6344dd94eb8c4f196b62b1",
            "6998c30504064ebd96dfc1cf74ff2450",
            "10abd83d12244d8d940d81748fe2141a",
            "19cb05f2ff6347d8b38ec20436a5cbb4",
            "2852f475c8c4473286c088809cf6c72c"
          ]
        },
        "outputId": "629d772c-b330-47ce-83ca-c711626d4199"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "260962a02c6743518add1429c3ddac39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f8690d09cf74d15acd489e32e1d6e05",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb69f168a43d451ab241a5dc7ed59486",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "635d11af27fb439baaad405699c91625",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCGQ7wf5S-g7"
      },
      "source": [
        "Each element of the dataset is a 2-tuple, consisting of the image of the digit, and its label. E.g.,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpK3WQnMSxDh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "36ad03e9-7425-4692-f821-1056a7444aab"
      },
      "source": [
        "image, label = mnist_train[13]\n",
        "print('This is a digit {}:'.format(label))\n",
        "image"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a digit 6:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+UlEQVR4nNWPoUtDYRTFTxC0CIJhQcS0l8aYGPSF8TBOhWX/gxXZUxSbQcOKzVWbJmGMLQ/TXDVtZbyhbGEWnwtazvEzCML7tq+teNLl/rjnngPMTV704mQ3b6w7UKotPq86LBvU2a7j0Cd16MwiFV1hrthcc7Gnz346uVn4m4rb5uHLAVfywPsQQHkdp7bp8qPRDnByHEnGfn1ADdLI1chJV52N5OERh5fw7jW+2wzUTcICeYFUg3F1MdOLq0nXcxJokwF88tp6WVENuZFCeJHCqSrGAN8m+7o0yH/YTXzSL8Wkxns2ArYmFEnaWX613xJ5Gwaz2P/QDwv6bXmT2FBqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F1A9F0CEED0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU7XDKYoTKER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296e7a92-340a-47fa-9c2d-dfa389a5f639"
      },
      "source": [
        "type(image)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PIL.Image.Image"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDgAtpx9TaJk"
      },
      "source": [
        "The image is given as a `PIL.Image`. To automatically obtain a `torch.Tensor`, we can add a [`torchvision.transforms.ToTensor` ](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor) transform when constructing the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyLnprU5TcPW"
      },
      "source": [
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
        "                                         transform=torchvision.transforms.ToTensor())  # the ToTensor transform converts PIL.Image to torch.Tensor"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_S3CyfdTvYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747eef17-f5d3-4dfb-a756-c2851ce5012e"
      },
      "source": [
        "image, label = mnist_train[13]\n",
        "print(type(image))\n",
        "print(image.shape)  # MNIST images are 28x28, and have a single channel representing brightness."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYxpkn2MTw8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2aeebf8-eb58-4e8f-d1c8-5684cd935cf1"
      },
      "source": [
        "print('This image has max={}'.format(image.max()), 'and min={}'.format(image.min()))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This image has max=1.0 and min=0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVlxkKkiUbT9"
      },
      "source": [
        "In deep learning, it is often a good idea to normalize network inputs to be centered around zero. We use the [`torchvision.transforms.Normalize`](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize) tranform to achieve this. Adding this transform, we construct the dataset as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUana9IuVQ_l"
      },
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,)),  # [0, 1] range => [-1, 1] range\n",
        "])\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
        "                                         transform=transform)\n",
        "mnist_val = torchvision.datasets.MNIST(root='./data', download=True, train=False,\n",
        "                                         transform=transform)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6732k7jSDze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d9125d-41aa-41c9-99d6-177ec923c952"
      },
      "source": [
        "print('training set size:\\t{}'.format(len(mnist_train)))\n",
        "print('validation set size:\\t{}'.format(len(mnist_val)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set size:\t60000\n",
            "validation set size:\t10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u_zABI6VzqM"
      },
      "source": [
        "We use the PyTorch `torch.utils.data.DataLoader` to automatically load batched data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfqlx7jDUK_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2849e9ea-13d3-4a66-8c47-c804005963b4"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, \n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,                   # shuffle training set\n",
        "                                           num_workers=4,                  # turns on multi-processing loading so training is not blocked by data loading\n",
        "                                           pin_memory=True)                # pin_memory allows faster transfer from CPU to GPU\n",
        "val_loader = torch.utils.data.DataLoader(mnist_val, \n",
        "                                         batch_size=batch_size, \n",
        "                                         num_workers=4, \n",
        "                                         pin_memory=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfwhWLUYa_jj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951eacee-471a-427f-f682-44de49c543d3"
      },
      "source": [
        "# Each element yielded by `train_loader` (a Python iterable) is still a 2-tuple, \n",
        "# but now consisting of a batched image tensor, and a batched label tensor.\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "print('batched image tensor shape: {}'.format(images.shape))\n",
        "print('batched label tensor shape: {}'.format(labels.shape))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batched image tensor shape: torch.Size([512, 1, 28, 28])\n",
            "batched label tensor shape: torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vtmrt4RWkYi"
      },
      "source": [
        "### Building the Network\n",
        "\n",
        "We will use a convolutional network for classification. The following architecture is adapted from the famous [LeNet-5](https://ieeexplore.ieee.org/document/726791) [1].\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[1] LeCun, Yann, et al. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE 86.11 (1998): 2278-2324."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sGKK2QIWgyI"
      },
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h260SpqhYkGL"
      },
      "source": [
        "net = MyNet().to(cuda0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQCUclhOZ4zS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fef289e-dbae-4b28-f34d-6cd0ae82b66b"
      },
      "source": [
        "# This network output a size 10 vector for each input image, as verified below \n",
        "# using a random input tensor.\n",
        "\n",
        "random_input = torch.randn(123, 1, 28, 28, device=cuda0)\n",
        "output = net(random_input)\n",
        "print(output.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([123, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2horeRUtaD7R"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "\n",
        "For classification, we will use the cross-entropy loss [`F.cross_entropy`](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html?highlight=cross_entropy#torch.nn.functional.cross_entropy) to train this network.\n",
        "\n",
        "We can write a function that iterates through the training set (via `train_loader`) and train for 1 epoch.\n",
        "\n",
        "The next exercise is to fill in the code below. You can use the following pytorch functions:\n",
        "\n",
        "* put data on GPU: [to](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html?highlight=#torch.to)\n",
        "* clear gradient: [zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html?highlight=zero_grad)\n",
        "* backward pass: [backward](https://pytorch.org/docs/stable/generated/torch.autograd.backward.html?highlight=backward#torch.autograd.backward)\n",
        "* update parameters with a gradient step: [step](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html?highlight=step#torch.optim.Optimizer.step)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_BrV5UGaIXj"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "def train(net, optim):\n",
        "    net.train()\n",
        "    for image, label in train_loader:\n",
        "      # put data onto GPU\n",
        "      img = image.cuda()\n",
        "      lab = label.cuda()\n",
        "\n",
        "      # clear gradient\n",
        "      net.zero_grad()\n",
        "\n",
        "      # forward through the network\n",
        "      output = net.forward(img)\n",
        "\n",
        "      # compute loss and gradient\n",
        "      loss = F.cross_entropy(output, lab)\n",
        "      loss.backward()\n",
        "\n",
        "      # update parameters\n",
        "      optim.step()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH7_TGTEcj2J"
      },
      "source": [
        "Let's also write a function that evaluates our network on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-wHW_UObnAk"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "def evaluate(net):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    net.eval()  # puts the network in eval mode. this is important when the \n",
        "                # network has layers that behaves differently in training and \n",
        "                # evaluation time, e.g., dropout and batch norm.\n",
        "    for image, label in val_loader:\n",
        "        # put data onto GPU\n",
        "        img = image.cuda()\n",
        "        label = label.cuda()\n",
        "        \n",
        "        with torch.no_grad():  # gradients are not tracked in this context manager\n",
        "                               # since we are evaluating, gradients are not needed \n",
        "                               # and we can save some time and GPU memory.\n",
        "              \n",
        "            # forward through the network, and get the predicted class\n",
        "            # FIXME!!!  (HINT: use .argmax(dim=-1))\n",
        "            #   `prediction` should be an integer vector of size equal to the batch size.\n",
        "            #   Remember that the network outputs logits of the prediction probabilities, \n",
        "            #   and that the higher the logits, the higher the probability.\n",
        "            prediction = net.forward(img).argmax(dim=-1)\n",
        "            \n",
        "            total += image.size(0)  # batch size\n",
        "            correct += (prediction == label).sum().item()  # `.item()` retreives a python number from a 1-element tensor\n",
        "            \n",
        "    return correct / total"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG7PVIwJdrKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5088a10f-02c1-4585-bb2d-6fc04ccf8eb4"
      },
      "source": [
        "# Without any training, the network accuracy matches that of random guessing: ~10%.\n",
        "\n",
        "print('At initialization, the network has accuracy {:.4f}%'.format(evaluate(net) * 100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At initialization, the network has accuracy 10.7200%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOd5vtSOeI1T"
      },
      "source": [
        "### Putting Everything Together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7n0x8idsDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575d4866-d2e9-4c4c-de7e-f4662a4c91da"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "\n",
        "# Fix the places with a `FIXME!!!\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "lr = 0.01\n",
        "\n",
        "optim = Adam(net.parameters(), lr=0.001)  # FIXME!!! Construct an optimizer (e.g., SGD) to optimize the network parameters with the above learning rate\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch: {}\\tValidation Accuracy: {:.4f}%'.format(epoch, evaluate(net) * 100))\n",
        "    train(net, optim)\n",
        "\n",
        "print('Done! \\tValidation Accuracy: {:.4f}%'.format(evaluate(net) * 100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\tValidation Accuracy: 98.8500%\n",
            "Epoch: 1\tValidation Accuracy: 99.1900%\n",
            "Epoch: 2\tValidation Accuracy: 99.2100%\n",
            "Epoch: 3\tValidation Accuracy: 99.2100%\n",
            "Epoch: 4\tValidation Accuracy: 99.2700%\n",
            "Epoch: 5\tValidation Accuracy: 99.2600%\n",
            "Epoch: 6\tValidation Accuracy: 99.2400%\n",
            "Epoch: 7\tValidation Accuracy: 99.2500%\n",
            "Epoch: 8\tValidation Accuracy: 99.2600%\n",
            "Epoch: 9\tValidation Accuracy: 99.3100%\n",
            "Done! \tValidation Accuracy: 99.2200%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikEuCz50os93"
      },
      "source": [
        "## Open-ended Exercises (not required)\n",
        "\n",
        "1. What could you do to make the accuracy higher and/or the training faster?  \n",
        "2. Adapt the code for another dataset (e.g., CIFAR-10 from [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html)).\n",
        "3. How dose your MNIST perform on [the USPS dataset](https://gist.github.com/SsnL/300865932b090d3f0798c2b961d371f9) (another black-white digits dataset)? Why?\n",
        "4. How many samples are actually needed to train a good MNIST classifier? Try subsample the training set (sampled a fraction of images per class) and plot validation accuracy vs. training set size.\n",
        "5. Use the [fast-gradient sign method](https://arxiv.org/abs/1412.6572) to attack your MNIST classifier! Why does your super great classifier now fail at a seemingly normal digit image?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB6zyzMjJ7yC"
      },
      "source": [
        "# Fast-Gradient Sign Attack example\n",
        "\n",
        "import PIL\n",
        "\n",
        "# Utility function\n",
        "def tensor2image(tensor):\n",
        "    return PIL.Image.fromarray((tensor.detach() * 127.5 + 128).clamp_(0, 255).to('cpu', torch.uint8).numpy()[0])\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5NfRhGoKn2H"
      },
      "source": [
        "# Get a data sample we want to attack\n",
        "\n",
        "data, label = mnist_val[245]\n",
        "data = data.to(cuda0)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiThr85eKqqp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "a23be8a5-8164-40f7-bd92-e02355741a71"
      },
      "source": [
        "# Look at the image\n",
        "\n",
        "tensor2image(data)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3UlEQVR4nGNgGCAwH5/kL2c8kmkXNbGKMzIwMDAwTFLczsD4n0HK/3DrUwwlKov+/r3y8O/fdf/tsRjAZm/PIJptH/QXmyQEWP/8ZYVLTnPfn2IGM+xyAff//Flx+dvly9nuGHKX/v79+/dKsykDg13viznsqJK3/lzqhTlH88EcVEkeUW44m2nDH5yuZij/8winXMnPR1pIXKe/f1VgbJVLf+8HIKtla33/ebY2AwODQ9y+T3/3akBEGWHSgk7aiZwMjHwsb1ZsOvIbTZKBgUFLi8GWY8tm3O4c3AAA5FBInrt1qJoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FDFDED78910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPF4q7v2Ktz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bb90ab-deb1-42e8-df97-3d8bb60ac869"
      },
      "source": [
        "# Label is...\n",
        "\n",
        "print('label is', label)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label is 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg-QAwN2LF0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d65625-6b7b-46f9-a3dc-af6a85a89f70"
      },
      "source": [
        "# Let's see what our trained network says about this image.\n",
        "\n",
        "\n",
        "# turn the network into eval mode\n",
        "net.eval()\n",
        "output = net(data.unsqueeze(0))  # .unsqueeze(0) insert a batch dimension so it looks like batched data\n",
        "prediction = output.argmax(-1)\n",
        "print('predicted class is', prediction.item())\n",
        "assert prediction.item() == label"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted class is 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS9BvDW8Mezz"
      },
      "source": [
        "# For fast-gradient sign attack to work, we need to get the gradient w.r.t. the input image. \n",
        "\n",
        "\n",
        "# Let's make it accept gradient first.\n",
        "data = data.requires_grad_()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7YRbcP8NBmR"
      },
      "source": [
        "# Compute the loss as usual\n",
        "loss = F.cross_entropy(net(data.unsqueeze(0)), torch.tensor([label], device=cuda0))\n",
        "\n",
        "# backprop, now to `data` as well\n",
        "loss.backward()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHqqxmvyNW3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2efcd4af-acbe-4f74-fa12-e81340b86b96"
      },
      "source": [
        "eps = 0.15\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Fast-gradient sign attack (aka gradient **ascent** for loss maximization)\n",
        "    new_data = (data + data.grad.sign() * eps).clamp_(-1, 1)  \n",
        "    new_prediction = net(new_data.unsqueeze(0)).argmax(-1)\n",
        "    print('The network predicts the attacked image as', new_prediction.item())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The network predicts the attacked image as 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MysfJQzBNZ2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "9ca997e1-3c74-4840-c39c-051474de5f07"
      },
      "source": [
        "# visualize the attacked image\n",
        "\n",
        "tensor2image(new_data)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABcUlEQVR4nHWSPWhUQRSFv022sJP4oYJgwAgxasDSxhVbEbGI2Nims9GAjb2/WFnZ2NiKnSFFGrcRAltoEdCQgEjWkAcXGzUQhbGYeW+fuE4xzNxz7zkz514AFRmzOk00/gW7EIytE7qEAURJyLfCNREGTxuMtroThtw8biMbtF8hLmxfoBF2VNoxDJ+dWNk49Ylj13bvDxtNA0XOL6e0872q+mmeEQddIFi7Mj/b/3Zj39MZMSwfrPNk7uvOVbU41hIXjrzafeBlxRy3W4sHveU9Dr4+ucXzzUFDaD4MU6qq/u0ZOHtv/XFtfIAhG4fern7sAyGTK18WITK/CnO1d8qLpNYti/plgQRP7v6cLmm5tPWBh+lHrwyAwLmqmsqJMjVMg14+luqlzc+PLqoLdz6k9P5wu3cql24N1n/9Tmn/5fVCaAdy7yWOnqF34M27JtKan5FEeybGTmVx7v9Y1hw58DfcMcbD1gOGknfrqwp/AAI9fRv5VizxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FDFDEDC30D0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rco3i5NO8Gp"
      },
      "source": [
        "# It still looks like a 3! But our network is now fooled..."
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaeiM9a-QEGL"
      },
      "source": [
        "Questions: \n",
        "+ Why does this happen? \n",
        "+ This method attacks the network so it predicts wrongly for this 3 image. Can you attack the network so it outputs a particular target class?"
      ]
    }
  ]
}